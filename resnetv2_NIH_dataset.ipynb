{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c7383d-3819-4fce-a8aa-4f2216ee2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "539a1c28-27dd-45fb-b890-83ffe1a3661c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1209718b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "842d13aa-dd2e-4535-9b78-b2ab31468d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Use M1 GPU if available, else use CUDA, else CPU\n",
    "# if cuda available up the N_PER_CLASS and epochs\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fe478c7-51af-4012-9678-33613e815b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.13).\n",
      "Dataset root: /Users/graysonrichard/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3\n",
      "        Image Index          Finding Labels  target\n",
      "0  00000001_000.png            Cardiomegaly       1\n",
      "1  00000001_001.png  Cardiomegaly|Emphysema       1\n",
      "2  00000001_002.png   Cardiomegaly|Effusion       1\n",
      "3  00000002_000.png              No Finding       0\n",
      "4  00000003_000.png                  Hernia       1\n"
     ]
    }
   ],
   "source": [
    "# Download dataset & load CSV\n",
    "dataset_root = kagglehub.dataset_download(\"nih-chest-xrays/data\")\n",
    "print(\"Dataset root:\", dataset_root)\n",
    "\n",
    "csv_path = os.path.join(dataset_root, \"Data_Entry_2017.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Set to binary classification\n",
    "df[\"target\"] = (df[\"Finding Labels\"] != \"No Finding\").astype(int)\n",
    "print(df[[\"Image Index\", \"Finding Labels\", \"target\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94bc296a-2e03-41c4-b77f-a0931ff900b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image coverage: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Map image filenames to paths\n",
    "image_path_map = {}\n",
    "for root, dirs, files in os.walk(dataset_root):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_path_map[fname] = os.path.join(root, fname)\n",
    "\n",
    "coverage = df[\"Image Index\"].isin(image_path_map.keys()).mean()\n",
    "print(f\"Image coverage: {coverage:.4f}\")\n",
    "\n",
    "# Keep only rows with actual image files\n",
    "df = df[df[\"Image Index\"].isin(image_path_map.keys())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ad8b516-459b-4951-9972-f339c981664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 4000\n",
      "target\n",
      "0    2000\n",
      "1    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create balanced subset of dataset(dataset is huge so this ensures it runs in an acceptable amount of time)\n",
    "N_PER_CLASS = 2000\n",
    "\n",
    "df_small_list = []\n",
    "for t in [0, 1]:\n",
    "    subset = df[df[\"target\"] == t]\n",
    "    n = min(len(subset), N_PER_CLASS)\n",
    "    df_small_list.append(subset.sample(n, random_state=SEED))\n",
    "\n",
    "df_small = pd.concat(df_small_list).reset_index(drop=True)\n",
    "\n",
    "print(\"Subset size:\", len(df_small))\n",
    "print(df_small[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5952f73a-126a-4a53-a5fe-73e9b48bf99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 2405 787 808\n"
     ]
    }
   ],
   "source": [
    "# Patient-level train/val/test split\n",
    "patients = df_small[\"Patient ID\"].unique()\n",
    "\n",
    "train_p, temp_p = train_test_split(patients, test_size=0.4, random_state=SEED)\n",
    "val_p, test_p = train_test_split(temp_p, test_size=0.5, random_state=SEED)\n",
    "\n",
    "def assign_split(pid):\n",
    "    if pid in train_p:\n",
    "        return \"train\"\n",
    "    elif pid in val_p:\n",
    "        return \"val\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "\n",
    "df_small[\"split\"] = df_small[\"Patient ID\"].apply(assign_split)\n",
    "\n",
    "train_df = df_small[df_small[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "val_df   = df_small[df_small[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "test_df  = df_small[df_small[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b092426-7282-48ed-82c6-c51fce1c1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class + transforms\n",
    "# image resize and augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=7),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9316cc40-cf81-425c-ac41-a24022c8230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, image_path_map, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_path_map = image_path_map\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row[\"Image Index\"]\n",
    "        img_path = self.image_path_map[img_name]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = int(row[\"target\"])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd6da711-f38f-4f69-9260-1a6ef35baee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 50 51\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0 # 0 for mac M1\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_df, image_path_map, train_transform)\n",
    "val_dataset = ChestXrayDataset(val_df, image_path_map, eval_transform)\n",
    "test_dataset = ChestXrayDataset(test_df, image_path_map, eval_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa2d79a7-44a7-472c-ae0f-f3ef6942d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet50 model (fine-tune last block + head)\n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze everything first\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last block + fc\n",
    "for name, param in resnet.named_parameters():\n",
    "    if name.startswith(\"layer4.\") or name.startswith(\"fc.\"):\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa9cd7b9-14cf-4bba-9824-4a00b00c0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace final layer with a slightly better head\n",
    "num_feats = resnet.fc.in_features\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(num_feats, 256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fad0ab96-a9b7-44b6-9178-7459fbe7a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only optimize trainable params\n",
    "trainable_params = [p for p in resnet.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(trainable_params, lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "970ea824-55d1-4d6b-a98d-ce9ad2ab859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/eval helpers\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs >= 0.5).long()\n",
    "        correct += (preds == labels.long()).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_probs = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs >= 0.5).long()\n",
    "            correct += (preds == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "            all_probs.extend(probs.cpu().numpy().flatten())\n",
    "    \n",
    "    return running_loss / total, correct / total, np.array(all_labels), np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab75a5-f9da-4845-b608-47663a04be44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6385, acc 0.649 | Val loss 0.6276, acc 0.661\n",
      "  -> New best model\n",
      "\n",
      "===== Epoch 2/20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5953, acc 0.687 | Val loss 0.6086, acc 0.676\n",
      "  -> New best model\n",
      "\n",
      "===== Epoch 3/20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5710, acc 0.709 | Val loss 0.6155, acc 0.673\n",
      "\n",
      "===== Epoch 4/20 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  70%|█████████████████████████▉           | 35/50 [00:15<00:06,  2.35it/s]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "NUM_EPOCHS = 20 # adjust based on speed of machin\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n===== Epoch {epoch+1}/{NUM_EPOCHS} =====\")\n",
    "    train_loss, train_acc = train_one_epoch(resnet, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc, _, _ = eval_one_epoch(resnet, val_loader, criterion, device)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Train loss {train_loss:.4f}, acc {train_acc:.3f} | \"\n",
    "          f\"Val loss {val_loss:.4f}, acc {val_acc:.3f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = resnet.state_dict().copy()\n",
    "        print(\"  -> New best model\")\n",
    "\n",
    "if best_state is not None:\n",
    "    resnet.load_state_dict(best_state)\n",
    "    print(\"\\nLoaded best validation model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fc781-4df1-4be7-bb0e-4403fab6eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best threshold on validation set\n",
    "val_loss, val_acc, y_val_true, y_val_prob = eval_one_epoch(resnet, val_loader, criterion, device)\n",
    "print(f\"\\nFinal VAL loss: {val_loss:.4f}, acc@0.5: {val_acc:.3f}\")\n",
    "\n",
    "best_thresh = 0.5\n",
    "best_f1 = 0.0\n",
    "best_acc = 0.0\n",
    "\n",
    "for thr in np.linspace(0.1, 0.9, 17):  # 0.1, 0.15, ..., 0.9\n",
    "    y_val_pred = (y_val_prob >= thr).astype(int)\n",
    "    f1 = f1_score(y_val_true.astype(int), y_val_pred)\n",
    "    acc = accuracy_score(y_val_true.astype(int), y_val_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_acc = acc\n",
    "        best_thresh = thr\n",
    "\n",
    "print(f\"Best VAL threshold: {best_thresh:.2f} | F1: {best_f1:.3f} | Acc: {best_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001f46a-03d5-4380-b744-f8b829e66841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test evaluation (0.5 and best threshold)\n",
    "test_loss, test_acc_05, y_true, y_prob = eval_one_epoch(resnet, test_loader, criterion, device)\n",
    "print(f\"\\nTest loss: {test_loss:.4f}, Test acc@0.5: {test_acc_05:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e3708-b003-43d3-ba40-2cb836b3d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5 threshold\n",
    "y_pred_05 = (y_prob >= 0.5).astype(int)\n",
    "cm_05 = confusion_matrix(y_true.astype(int), y_pred_05)\n",
    "print(\"\\n[Threshold = 0.5] Confusion matrix (rows=true, cols=pred):\")\n",
    "print(cm_05)\n",
    "\n",
    "print(\"\\n[Threshold = 0.5] Classification report:\")\n",
    "print(classification_report(\n",
    "    y_true.astype(int),\n",
    "    y_pred_05,\n",
    "    target_names=[\"No Finding\", \"Any Finding\"]\n",
    "))\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "except ValueError:\n",
    "    print(\"ROC-AUC could not be computed (only one class present).\")\n",
    "\n",
    "# best validation threshold\n",
    "y_pred_best = (y_prob >= best_thresh).astype(int)\n",
    "test_acc_best = accuracy_score(y_true.astype(int), y_pred_best)\n",
    "test_f1_best = f1_score(y_true.astype(int), y_pred_best)\n",
    "cm_best = confusion_matrix(y_true.astype(int), y_pred_best)\n",
    "\n",
    "print(f\"\\n[Threshold = {best_thresh:.2f}] Test acc: {test_acc_best:.3f}, F1: {test_f1_best:.3f}\")\n",
    "print(\"[Threshold = {:.2f}] Confusion matrix (rows=true, cols=pred):\".format(best_thresh))\n",
    "print(cm_best)\n",
    "\n",
    "print(\"\\n[Threshold = {:.2f}] Classification report:\".format(best_thresh))\n",
    "print(classification_report(\n",
    "    y_true.astype(int),\n",
    "    y_pred_best,\n",
    "    target_names=[\"No Finding\", \"Any Finding\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585fe1a-4fd1-4fa9-9a3f-f878f881aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6da640-e3aa-4826-a204-71d295540f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgroup evaluation: Age & Gender\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336c706-b8bf-432b-8026-ad27cf79128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df contains columns like: Patient Age, Patient Gender\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Attach predictions to test dataframe\n",
    "test_df[\"y_true\"] = y_true\n",
    "test_df[\"y_prob\"] = y_prob\n",
    "test_df[\"y_pred_05\"] = (y_prob >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27464adf-fa39-4dc5-88fc-2f82d54d4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender groups\n",
    "print(\"\\n===== Subgroup Performance by Gender =====\")\n",
    "for gender in sorted(test_df[\"Patient Gender\"].unique()):\n",
    "    group = test_df[test_df[\"Patient Gender\"] == gender]\n",
    "    if len(group) < 5:\n",
    "        continue\n",
    "\n",
    "    y_t = group[\"y_true\"].astype(int).values\n",
    "    y_p = group[\"y_pred_05\"].astype(int).values\n",
    "    y_prob_g = group[\"y_prob\"].values\n",
    "\n",
    "    acc = accuracy_score(y_t, y_p)\n",
    "    f1  = f1_score(y_t, y_p)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_t, y_prob_g)\n",
    "    except:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\nGender: {gender}\")\n",
    "    print(f\"  Count: {len(group)}\")\n",
    "    print(f\"  Accuracy: {acc:.3f}\")\n",
    "    print(f\"  F1 Score: {f1:.3f}\")\n",
    "    print(f\"  ROC-AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84af1c-19a4-4381-a810-3651da64fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age groups\n",
    "print(\"\\n===== Subgroup Performance by Age =====\")\n",
    "bins = [0, 20, 40, 60, 80, 120]\n",
    "labels = [\"0-20\", \"21-40\", \"41-60\", \"61-80\", \"81+\"]\n",
    "\n",
    "test_df[\"AgeGroup\"] = pd.cut(test_df[\"Patient Age\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "for ag in labels:\n",
    "    group = test_df[test_df[\"AgeGroup\"] == ag]\n",
    "    if len(group) < 5:\n",
    "        continue\n",
    "\n",
    "    y_t = group[\"y_true\"].astype(int).values\n",
    "    y_p = group[\"y_pred_05\"].astype(int).values\n",
    "    y_prob_g = group[\"y_prob\"].values\n",
    "\n",
    "    acc = accuracy_score(y_t, y_p)\n",
    "    f1  = f1_score(y_t, y_p)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_t, y_prob_g)\n",
    "    except:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\nAge Group: {ag}\")\n",
    "    print(f\"  Count: {len(group)}\")\n",
    "    print(f\"  Accuracy: {acc:.3f}\")\n",
    "    print(f\"  F1 Score: {f1:.3f}\")\n",
    "    print(f\"  ROC-AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40a0bb-4095-46e5-8a38-a02097008fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM Heatmap Generation for a Few Test Images\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# useing the last conv layer in layer4 of ResNet50\n",
    "target_layer = resnet.layer4[-1].conv3\n",
    "\n",
    "# Global holders for activations and gradients\n",
    "gradcam_activations = []\n",
    "gradcam_gradients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e24c8-536a-4ba3-a520-d0a74a39c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_hook(module, input, output):\n",
    "    # output: (N, C, H, W)\n",
    "    gradcam_activations.append(output.detach())\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    # grad_output[0]: (N, C, H, W)\n",
    "    gradcam_gradients.append(grad_output[0].detach())\n",
    "\n",
    "def generate_gradcam(model, img_tensor, target_layer):\n",
    "    # Clear previous\n",
    "    gradcam_activations.clear()\n",
    "    gradcam_gradients.clear()\n",
    "\n",
    "    fwd_handle = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    bwd_handle = target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Forward\n",
    "    output = model(img_tensor)\n",
    "    prob = torch.sigmoid(output)[0, 0].item()\n",
    "\n",
    "    # Backward\n",
    "    model.zero_grad()\n",
    "    output[0, 0].backward()\n",
    "\n",
    "    # Get activations and gradients from hooks\n",
    "    acts = gradcam_activations[0]\n",
    "    grads = gradcam_gradients[0]\n",
    "\n",
    "    fwd_handle.remove()\n",
    "    bwd_handle.remove()\n",
    "    \n",
    "    acts = acts.squeeze(0).cpu().numpy()\n",
    "    grads = grads.squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Channel weights\n",
    "    weights = grads.mean(axis=(1, 2))\n",
    "\n",
    "    # Weighted sum of activations\n",
    "    cam = np.zeros(acts.shape[1:], dtype=np.float32)  # (H, W)\n",
    "    for c, w in enumerate(weights):\n",
    "        cam += w * acts[c]\n",
    "\n",
    "    # ReLU + normalize\n",
    "    cam = np.maximum(cam, 0)\n",
    "    if cam.max() > 0:\n",
    "        cam = cam / cam.max()\n",
    "\n",
    "    # Resize to 224x224\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "\n",
    "    return cam, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b168e7-9d01-4f50-9f90-0592ded74ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few test samples\n",
    "indices_to_show = [0, 7, 10, 15, 20]\n",
    "\n",
    "for i in indices_to_show:\n",
    "    if i >= len(test_dataset):\n",
    "        continue\n",
    "\n",
    "    img, label = test_dataset[i]\n",
    "    heatmap, prob = generate_gradcam(resnet, img, target_layer)\n",
    "\n",
    "    # Convert tensor to [0,1] RGB for display\n",
    "    img_np = img.permute(1, 2, 0).cpu().numpy()\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Original (Label={int(label)})\")\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Grad-CAM (Pred Prob={prob:.2f})\")\n",
    "    plt.imshow(img_np, alpha=0.5)\n",
    "    plt.imshow(heatmap, cmap=\"jet\", alpha=0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656214d-852b-41f7-8032-09e8f0c64a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
